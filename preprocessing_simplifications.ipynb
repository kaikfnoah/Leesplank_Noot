{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b41dd1e6-08ec-4d7a-97ea-bc61bfdceecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers\n",
    "# !pip install --upgrade jupyterlab_widgets\n",
    "# !jupyter lab build\n",
    "# !pip install python-Levenshtein\n",
    "# !pip install ipywidgets --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35a87d6-dfc3-4eb6-afd4-1e0a16c2e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9348edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (API keys) from .env file\n",
    "load_dotenv()\n",
    "HUGGINFACE_TOKEN = os.getenv(\"HUGGINFACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ce64d55-212b-4870-96b9-cc7ecc83254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for preprocessing\n",
    "\n",
    "# Function to calculate structural complexity\n",
    "def length(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Function to calculate Levenshtein distance\n",
    "def calculate_levenshtein(prompt, result):\n",
    "    return Levenshtein.distance(prompt, result)\n",
    "\n",
    "def is_list_like(text):\n",
    "    # Regex to find non-word, non-space characters\n",
    "    non_word_chars = re.findall(r'[^\\w\\s]', text)\n",
    "    # Split text into words\n",
    "    words = re.findall(r'\\w+', text)\n",
    "    \n",
    "    # Calculate ratio: number of non-word chars to words\n",
    "    ratio = len(non_word_chars) / len(words) if len(words) > 0 else 0\n",
    "    \n",
    "    # You can adjust this threshold based on your data\n",
    "    return ratio > 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "837a8ce3-1b88-48db-b654-49bc1cde4361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 2867757/2867757 [00:23<00:00, 120666.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## Load the dataset and shuffle it\n",
    "ds = load_dataset(\"UWV/Leesplank_NL_wikipedia_simplifications\", split=\"train\")\n",
    "ds = ds.shuffle(seed=42)\n",
    "\n",
    "# Convert to pandas dataframe for deduplication\n",
    "df = ds.to_pandas()\n",
    "\n",
    "# Remove duplicates and reset index\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f73be2e9-c02f-4647-aa3c-3272bb0ab0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771144, 5)\n"
     ]
    }
   ],
   "source": [
    "df['prompt_lenght'] = df['prompt'].apply(length)\n",
    "df['result_lenght'] = df['result'].apply(length)\n",
    "df['levenshtein_distance'] = df.apply(lambda row: calculate_levenshtein(row['prompt'], row['result']), axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09bd54d-969c-413e-b14d-a272a546908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing prompts shorter than 7 words\n",
    "df = df[df['prompt_lenght'] >= 7]\n",
    "# Order by Levenstein distance\n",
    "df = df.sort_values(by='levenshtein_distance', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11834e16-7465-4e5e-8d9b-f181365d51d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2694555, 5)\n"
     ]
    }
   ],
   "source": [
    "df = df[~df['prompt'].apply(is_list_like)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4419ce40-3ff6-4bc5-98be-9b0c8583f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add [S2S] prefix to prompt\n",
    "df['prompt'] = '[S2S] ' + df['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d22eb0c2-9c3b-4cf1-9cb3-632e034bc55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    prompt  \\\n",
      "1945736  [S2S] Jan Waaijer is getrouwd en heeft twee ki...   \n",
      "2001729       [S2S] Reinout III was een van zijn kinderen.   \n",
      "1141980      [S2S] Hij is de zoon van André Van Den Bosch.   \n",
      "2677840    [S2S] Beute is getrouwd en heeft drie kinderen.   \n",
      "1624     [S2S] Herrera is getrouwd met Lourdes Betia Cu...   \n",
      "\n",
      "                                                  result  \n",
      "1945736  Jan Waaijer is getrouwd en heeft twee kinderen.  \n",
      "2001729           Reinout III was een van zijn kinderen.  \n",
      "1141980          Hij is de zoon van André Van Den Bosch.  \n",
      "2677840        Beute is getrouwd en heeft drie kinderen.  \n",
      "1624        Herrera is getrouwd met Lourdes Betia Cuico.  \n"
     ]
    }
   ],
   "source": [
    "df = df[[\"prompt\", \"result\"]]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60ab0dfe-bfbd-40fe-9435-9a009dea0482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to Hugging Face Dataset and select only needed columns\n",
    "ds = Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8f6c6d-94ba-4c2a-a9ca-554b2f512e1f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e7c3d7e-c46b-4bc2-891b-5a4b0d49d350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\ElinedeKinkelder\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ff11dc9a614475b630f945ea452e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02de1b1379a1490d82253a4d83c8344e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/674 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744a07748d694da49fe29dfef676d146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/674 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94327a897fd49d994311efb0468dfc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/674 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9d2862d17e423d8620da8f0466c04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/674 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/UWV/Leesplank_NL_wikipedia_simplifications_preprocessed/commit/b995946b7e8d2412a7a65d9a2e5bb7c67f25f85a', commit_message='Upload dataset', commit_description='', oid='b995946b7e8d2412a7a65d9a2e5bb7c67f25f85a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/UWV/Leesplank_NL_wikipedia_simplifications_preprocessed', endpoint='https://huggingface.co', repo_type='dataset', repo_id='UWV/Leesplank_NL_wikipedia_simplifications_preprocessed'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(HUGGINGFACE_TOKEN)\n",
    "\n",
    "# Push the dataset to Hugging Face Hub\n",
    "ds.push_to_hub(\"UWV/Leesplank_NL_wikipedia_simplifications_preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b1266a-ec40-44de-8e9a-b376666a522e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
