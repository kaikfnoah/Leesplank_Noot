{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cbb53e175f4e909a9999d3d3a94aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = \"auto\"\n",
    "model_path = \"ibm-granite/granite-3.0-2b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# drop device_map if running on CPU\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "## Load the dataset\n",
    "ds = load_dataset(\"UWV/Leesplank_NL_wikipedia_simplifications_preprocessed\", split='test')\n",
    "df = ds.to_pandas()\n",
    "# ds = ds.shuffle(seed=42)\n",
    "\n",
    "# random_row = [i for i in ds.take(1)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = \"Vereenvoudig een Nederlandse alinea tot één duidelijke en aantrekkelijke tekst, geschikt voor volwassenen die Nederlands als tweede taal spreken, met woorden uit de 'basiswoordenlijst Amsterdamse kleuters.' Behoud directe citaten, maak dialogen eenvoudiger en leg culturele verwijzingen, uitdrukkingen en technische termen natuurlijk uit in de tekst. Pas de volgorde van informatie aan voor betere eenvoud, aantrekkelijkheid en leesbaarheid. Probeer geen komma’s of verkleinwoorden te gebruiken.\"\n",
    "# # instruction = \"Simplify a Dutch paragraph directly into a single, clear, and engaging text suitable for adult readers that speak Dutch as a second language, using words from the 'basiswoordenlijst Amsterdamse kleuters.' Maintain direct quotes, simplify dialogue, explain cultural references, idioms, and technical terms naturally within the text. Adjust the order of information for improved simplicity, engagement, and readability. Attempt to not use any commas or diminutives.\"\n",
    "# # instruction = \"Vereenvoudig een Nederlandse alinea tot één duidelijke en aantrekkelijke tekst, geschikt voor volwassenen die Nederlands als tweede taal spreken, met woorden uit de 'basiswoordenlijst Amsterdamse kleuters.' Behoud directe citaten, maak dialogen eenvoudiger en leg culturele verwijzingen, uitdrukkingen en technische termen natuurlijk uit in de tekst. Pas de volgorde van informatie aan voor betere eenvoud, aantrekkelijkheid en leesbaarheid. Probeer geen komma’s of verkleinwoorden te gebruiken.\"\n",
    "# sentence = random_row['prompt']\n",
    "\n",
    "# # prompt = '<instruction>' + instruction + '</instruction><simplify>' + sentence + '</simplify>'\n",
    "\n",
    "# prompt = f'{sentence}'\n",
    "\n",
    "# # prompt = f'Tune if necessary the following prompt: {instruction}'\n",
    "\n",
    "# chat = [\n",
    "#     { \"role\": \"system\", \"content\": system_prompt},  # Adding system instruction\n",
    "#     { \"role\": \"user\", \"content\": prompt},    # Your existing user prompt\n",
    "# ]\n",
    "\n",
    "chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# tokenize the text\n",
    "input_tokens = tokenizer(chat, return_tensors=\"pt\").to('cpu')\n",
    "\n",
    "# generate output tokens\n",
    "output = model.generate(**input_tokens, \n",
    "                        max_new_tokens=500)\n",
    "\n",
    "# decode output tokens into text\n",
    "output_text = tokenizer.batch_decode(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting benchmarking on dataset 1 (size: 89594)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset 1: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instruction                                             Vereenvoudig: \n",
      "prompt               Arthur Dowers is getrouwd en heeft drie kinderen.\n",
      "result               Arthur Dowers is getrouwd en heeft drie kinderen.\n",
      "__index_level_0__                                              2486264\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 49\u001b[0m\n\u001b[1;32m     43\u001b[0m template \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     44\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_prompt},  \u001b[38;5;66;03m# Adding system instruction\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt},  \u001b[38;5;66;03m# Your existing user prompt\u001b[39;00m\n\u001b[1;32m     46\u001b[0m ]\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Tokenize the input and move it to the selected device\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m chat \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mapply_chat_template(template, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m input_tokens \u001b[38;5;241m=\u001b[39m tokenizer(chat, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Generate output tokens\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "from evaluate import load\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "df_size = len(df)\n",
    "sari = load(\"sari\")\n",
    "\n",
    "# Split dataset into three parts\n",
    "df_0 = df[:int(df_size*(1/3))]\n",
    "df_1 = df[int(df_size*(1/3)):int(df_size*(2/3))]\n",
    "df_2 = df[int(df_size*(2/3)):]\n",
    "\n",
    "datasets = [df_0, df_1, df_2]\n",
    "system_prompt = (\"Vereenvoudig een Nederlandse alinea tot één duidelijke en aantrekkelijke tekst, \"\n",
    "                 \"geschikt voor volwassenen die Nederlands als tweede taal spreken, met woorden uit de \"\n",
    "                 \"'basiswoordenlijst Amsterdamse kleuters.' Behoud directe citaten, maak dialogen eenvoudiger \"\n",
    "                 \"en leg culturele verwijzingen, uitdrukkingen en technische termen natuurlijk uit in de tekst. \"\n",
    "                 \"Pas de volgorde van informatie aan voor betere eenvoud, aantrekkelijkheid en leesbaarheid. \"\n",
    "                 \"Probeer geen komma’s of verkleinwoorden te gebruiken.\")\n",
    "\n",
    "sari_scores, sari_scores_avg = [], []\n",
    "sari_errors = 0\n",
    "\n",
    "# Start the overall timer\n",
    "start_time_total = time.time()\n",
    "\n",
    "for idx, data in enumerate(datasets):\n",
    "    start_time_data = time.time()  # Timer for each dataset\n",
    "\n",
    "    print(f\"Starting benchmarking on dataset {idx + 1} (size: {len(data)})\")\n",
    "\n",
    "    sari_scores_data = []\n",
    "\n",
    "    # Use tqdm for a progress bar over rows in the dataset\n",
    "    for row_idx, row in tqdm(data.iterrows(), desc=f\"Processing dataset {idx + 1}\"):\n",
    "        prompt = row['prompt']\n",
    "        \n",
    "        template = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # Adding system instruction\n",
    "            {\"role\": \"user\", \"content\": prompt},  # Your existing user prompt\n",
    "        ]\n",
    "        \n",
    "        # Tokenize the input and move it to the selected device\n",
    "        chat = tokenizer.apply_chat_template(template, tokenize=False, add_generation_prompt=True)\n",
    "        input_tokens = tokenizer(chat, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        # Generate output tokens\n",
    "        output = model.generate(**input_tokens, max_new_tokens=500)\n",
    "        \n",
    "        # Decode output tokens into text\n",
    "        output_text = tokenizer.batch_decode(output)\n",
    "        \n",
    "        # Extract the output using regex\n",
    "        match = re.search(r'<\\|start_of_role\\|>assistant<\\|end_of_role\\|>(.*?)<\\|end_of_text\\|>', output_text[0])\n",
    "        if match:\n",
    "            output = match.group(1).replace('\\\"', '').replace('\\\\', '')\n",
    "        \n",
    "        # Compute SARI score\n",
    "        try:\n",
    "            sari_score = sari.compute(sources=[prompt], predictions=[output], references=[[row['result']]])['sari']\n",
    "            sari_scores_data.append(sari_score)\n",
    "        except ValueError as e:\n",
    "            sari_errors += 1\n",
    "            print(f'Error: {e}')\n",
    "            print(f'This originates from the following row: {prompt}')\n",
    "\n",
    "    # Store the individual dataset scores and average\n",
    "    sari_scores.append(sari_scores_data)\n",
    "    sari_scores_avg.append(sum(sari_scores_data) / len(sari_scores_data))\n",
    "\n",
    "    # Print time taken for each dataset\n",
    "    elapsed_time_data = time.time() - start_time_data\n",
    "    print(f\"Finished dataset {idx + 1} in {elapsed_time_data:.2f} seconds\")\n",
    "\n",
    "# Final time and results\n",
    "elapsed_time_total = time.time() - start_time_total\n",
    "print(f\"Processing completed in {elapsed_time_total:.2f} seconds\")\n",
    "print(f\"SARI scores averages: {sari_scores_avg}\")\n",
    "print(f\"There were {sari_errors} rows that gave an error.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|start_of_role|>system<|end_of_role|>Vereenvoudig een Nederlandse alinea tot één duidelijke en aantrekkelijke tekst, geschikt voor volwassenen die Nederlands als tweede taal spreken, met woorden uit de \\'basiswoordenlijst Amsterdamse kleuters.\\' Behoud directe citaten, maak dialogen eenvoudiger en leg culturele verwijzingen, uitdrukkingen en technische termen natuurlijk uit in de tekst. Pas de volgorde van informatie aan voor betere eenvoud, aantrekkelijkheid en leesbaarheid. Probeer geen komma’s of verkleinwoorden te gebruiken.<|end_of_text|>\\n<|start_of_role|>user<|end_of_role|>Montes Abalde leerde al op 10-jarige leeftijd in de muziekschool van de \\\\\"Banda de Música Agrupación Musical Atlántida de Matamá\\\\\" de trombone te bespelen. Vervolgens studeerde hij trombone en compositie aan het \\\\\"Conservatorio de Música de Vigo\\\\\". Hij behaalde zijn diploma\\'s voor trombone in oktober 2005 en voor compositie in maart 2007. Later volgde hij ook de muziekopleiding aan de universiteit van Vigo. Naast zijn \\\\\"Banda de Música Agrupación Musical Atlántida de Matamá\\\\\" is hij ook lid in het \\\\\"Orquestra Clásica de Vigo\\\\\".<|end_of_text|>\\n<|start_of_role|>assistant<|end_of_role|>Montes Abalde begon met de trombone op 10 jaar oud in de muziekschool van de \\\\\"Banda de Música Agrupación Musical Atlántida de Matamá\\\\\". Hij studeerde vervolgens trombone en compositie aan het \\\\\"Conservatorio de Música de Vigo\\\\\" en behaalde zijn diploma\\'s in oktober 2005 en maart 2007. Naast zijn band is hij ook lid van het \\\\\"Orquestra Clásica de Vigo\\\\\".<|end_of_text|>']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montes Abalde begon met de trombone op 10 jaar oud in de muziekschool van de Banda de Música Agrupación Musical Atlántida de Matamá. Hij studeerde vervolgens trombone en compositie aan het Conservatorio de Música de Vigo en behaalde zijn diploma's in oktober 2005 en maart 2007. Naast zijn band is hij ook lid van het Orquestra Clásica de Vigo.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Regular expression to extract the text between the markers\n",
    "match = re.search(r'<\\|start_of_role\\|>assistant<\\|end_of_role\\|>(.*?)<\\|end_of_text\\|>', output_text[0])\n",
    "\n",
    "if match:\n",
    "    output = match.group(1).replace('\\\"', '').replace('\\\\', '')\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toen Montes Abalde tien jaar oud was, begon hij trombone te spelen bij de muziekschool van de Banda de Música Agrupación Musical Atlántida de Matamá. Hij ging verder met zijn muziekstudie aan het Conservatorio de Música de Vigo, waar hij leerde hoe hij trombone moest spelen en hoe hij muziek kon componeren. In oktober 2005 kreeg hij zijn diploma voor trombone en in maart 2007 voor compositie. Daarna ging hij naar de universiteit van Vigo voor meer muzieklessen. Montes Abalde speelt niet alleen bij de Banda de Música Agrupación Musical Atlántida de Matamá, maar ook bij het Orquestra Clásica de Vigo.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_row['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARI\n",
    "from evaluate import load\n",
    "sari = load(\"sari\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "Requirement already satisfied: regex in /home/vscode/.local/lib/python3.12/site-packages (from sacremoses) (2024.11.6)\n",
      "Collecting click (from sacremoses)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in /home/vscode/.local/lib/python3.12/site-packages (from sacremoses) (1.4.2)\n",
      "Requirement already satisfied: tqdm in /home/vscode/.local/lib/python3.12/site-packages (from sacremoses) (4.67.0)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vscode/.local/lib/python3.12/site-packages (from sacrebleu) (2.1.3)\n",
      "Collecting colorama (from sacrebleu)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Downloading lxml-5.3.0-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (3.8 kB)\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading lxml-5.3.0-cp312-cp312-manylinux_2_28_aarch64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: tabulate, portalocker, lxml, colorama, click, sacremoses, sacrebleu\n",
      "Successfully installed click-8.1.7 colorama-0.4.6 lxml-5.3.0 portalocker-3.0.0 sacrebleu-2.4.3 sacremoses-0.1.1 tabulate-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sacremoses sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sari': 50.51047164345278}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sari_score = sari.compute(sources=[sentence], predictions=[output], references=[[random_row['result']]])\n",
    "sari_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
